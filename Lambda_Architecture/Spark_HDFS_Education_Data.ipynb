{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux Commands\n",
    "\n",
    "### cd into project 2 directory\n",
    "`cd ~/w205/project-2-juliejlai`\n",
    "\n",
    "### curl down json file into project 2 directory:\n",
    "`curl -L -o assessment-attempts-20180128-121051-nested.json https://goo.gl/ME6hjp`\n",
    "\n",
    "### copy yml file:\n",
    "`cp ~/w205/course-content/08-Querying-Data/docker-compose.yml ~/w205/project-2-juliejlai`\n",
    "\n",
    "### spin/bring up docker:\n",
    "`docker-compose up -d`\n",
    "\n",
    "### check docker:\n",
    "`docker-compose ps`\n",
    "`docker ps -a`\n",
    "\n",
    "### create a mirror console / start kafka logs:\n",
    "`docker-compose logs -f kafka`\n",
    "\n",
    "### create a topic (name = assessments):\n",
    "`docker-compose exec kafka kafka-topics --create --topic assessments --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181`\n",
    "\n",
    "### check topic:\n",
    "`docker-compose exec kafka kafka-topics --describe --topic assessments --zookeeper zookeeper:32181`\n",
    "\n",
    "### write messages using kafka cat:\n",
    "`docker-compose exec mids bash -c \"cat /w205/project-2-juliejlai/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t assessments\"`\n",
    "\n",
    "### read the message:\n",
    "`docker-compose exec mids bash -c \"kafkacat -C -b kafka:29092 -t assessments -o beginning -e\"`\n",
    "\n",
    "### spin up pyspark:\n",
    "`docker-compose exec spark pyspark`\n",
    "\n",
    "### or bring up jupyter notebook:\n",
    "`docker-compose exec spark bash`\n",
    "#### Create a symbolic link from the spark directory to /w205 :\n",
    "`ln -s /w205 w205`\n",
    "`exit`\n",
    "`docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root' pyspark`\n",
    "\n",
    "### shut down docker\n",
    "`docker-compose down`\n",
    "`docker-compose ps`\n",
    "`docker ps -a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Messages in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrolling the json (using Kevin's starter code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_assessments = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"kafka:29092\").option(\"subscribe\",\"assessments\").option(\"startingOffsets\", \"earliest\").option(\"endingOffsets\", \"latest\").load() \n",
    "raw_assessments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assessments = raw_assessments.select(raw_assessments.value.cast('string'))\n",
    "extracted_assessments = assessments.rdd.map(lambda x: Row(**json.loads(x.value))).toDF()\n",
    "extracted_assessments.registerTempTable('assessments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: How many assessments are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|num_assessments|\n",
      "+---------------+\n",
      "|           3280|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_assessments = spark.sql(\"select count(*) as `num_assessments` from assessments\")\n",
    "num_assessments.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There are 3280 assessments in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: What's the name of your Kafka topic? How did you come up with that name?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The name of my Kafka topic is 'assessments'. We chose this name in class because it is has signficance to the dataset, which is assessments data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: How many people took Learning Git?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|count_learning_git|\n",
      "+------------------+\n",
      "|               394|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_git = spark.sql(\"select count(exam_name) as `count_learning_git` from assessments where exam_name = 'Learning Git'\")\n",
    "learn_git.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 394 people took Learning Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: What is the least common course taken? And the most common?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-----+\n",
      "|exam_name                                        |count|\n",
      "+-------------------------------------------------+-----+\n",
      "|Learning to Visualize Data with D3.js            |1    |\n",
      "|Learning Git                                     |394  |\n",
      "|Nulls, Three-valued Logic and Missing Information|1    |\n",
      "|Native Web Apps for Android                      |1    |\n",
      "|Operating Red Hat Enterprise Linux Servers       |1    |\n",
      "+-------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "com_course = spark.sql(\"select exam_name, count(exam_name) as `count` from assessments group by exam_name \\\n",
    "                       having count(exam_name) = (select max(count) from \\\n",
    "                       (select exam_name, count(exam_name) as `count` from assessments group by exam_name)) \\\n",
    "                       or count(exam_name) = (select min(count) from \\\n",
    "                       (select exam_name, count(exam_name) as `count` from assessments group by exam_name))\")\n",
    "com_course.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The least common courses taken are 'Learning to Visualize Data with D3.js', 'Nulls, Three-valued Logic and Missing Information', 'Native Web Apps for Android', 'Operating Red Hat Enterprise Linux Servers' with only 1 person taking each course. The most common course taken is 'Learning Git' with 394 people taking the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: On average, how many questions are there per exam? Exams with the lowest number of questions? Exams with the highest number of questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to handle \"holes\" in json data (using Kevin's starter code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_lambda_correct_total(x):\n",
    "    \n",
    "    raw_dict = json.loads(x.value)\n",
    "    my_list = []\n",
    "    \n",
    "    if \"sequences\" in raw_dict:\n",
    "        \n",
    "        if \"counts\" in raw_dict[\"sequences\"]:\n",
    "            \n",
    "            if \"correct\" in raw_dict[\"sequences\"][\"counts\"] and \"total\" in raw_dict[\"sequences\"][\"counts\"]:\n",
    "                    \n",
    "                my_dict = {\"exam\": raw_dict[\"exam_name\"],\n",
    "                           \"correct\": raw_dict[\"sequences\"][\"counts\"][\"correct\"], \n",
    "                           \"total\": raw_dict[\"sequences\"][\"counts\"][\"total\"]}\n",
    "                my_list.append(Row(**my_dict))\n",
    "    \n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_correct_total = assessments.rdd.flatMap(my_lambda_correct_total).toDF()\n",
    "my_correct_total.registerTempTable('ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-----+\n",
      "|exam                                             |total|\n",
      "+-------------------------------------------------+-----+\n",
      "|View Updating                                    |1.0  |\n",
      "|Introduction to Hadoop YARN                      |1.0  |\n",
      "|Nullology                                        |1.0  |\n",
      "|Introduction to Apache Hive                      |1.0  |\n",
      "|Nulls, Three-valued Logic and Missing Information|1.0  |\n",
      "|Git Fundamentals for Web Developers              |1.0  |\n",
      "|Operating Red Hat Enterprise Linux Servers       |20.0 |\n",
      "+-------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_q = spark.sql('select exam, avg(total) as `total` from ct group by exam\\\n",
    "                    having total = (select max(total) from ct) \\\n",
    "                    or total = (select min(total) from ct)')\n",
    "num_q.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|            avg_q|\n",
      "+-----------------+\n",
      "|4.489160305343511|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_q = spark.sql('select avg(total) as `avg_q` from ct')\n",
    "avg_q.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The average number of questions on an exam is 4.489. The exam with the highest number of questions (20 questions) is 'Operating Red Hat Enterprise Linux Servers'. The exams with the lowest number of questions (1 question) are 'View Updating', 'Introduction to Hadoop YARN', 'Nullology', 'Introduction to Apache Hive', 'Nulls, Three-valued Logic and Missing Information', and 'Git Fundamentals for Web Developers'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: What are the average score and standard deviation per exam? What are the lowest and highest average scores? Is there a correlation between the number of questions on an exam and the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-------------------+-----+\n",
      "|                exam|        avg_score|                std|num_q|\n",
      "+--------------------+-----------------+-------------------+-----+\n",
      "|Learning to Visua...|            100.0|                NaN|  3.0|\n",
      "|Nulls, Three-valu...|            100.0|                NaN|  1.0|\n",
      "|The Closed World ...|            100.0|                0.0|  2.0|\n",
      "|Learning SQL for ...|97.72727272727273|0.07537783614444094|  4.0|\n",
      "|Introduction to J...|87.59493670886073|0.18833172378627616|  5.0|\n",
      "|Introduction to A...|83.33333333333334| 0.1767766952966369|  4.0|\n",
      "|Introduction to A...|83.33333333333334|0.27888667551135854|  3.0|\n",
      "|Cloud Native Arch...|80.00000000000003|0.22677868380553634|  5.0|\n",
      "|Getting Ready for...|80.00000000000001|                0.2|  5.0|\n",
      "|Understanding the...|78.57142857142857|0.10101525445522103|  7.0|\n",
      "|Introduction to A...|76.92307692307693|0.21014172398537173|  3.0|\n",
      "|Beginning Program...|76.58227848101265|0.23459516463275298|  4.0|\n",
      "|Learning Apache H...|          76.5625|0.21347814095749165|  4.0|\n",
      "|Refactor a Monoli...|76.47058823529412|0.30651957256595064|  3.0|\n",
      "|Starting a Grails...|             75.0|               0.25|  4.0|\n",
      "|Git Fundamentals ...|             75.0| 0.4409585518440985|  1.0|\n",
      "|Introduction to H...|             75.0| 0.4629100498862757|  1.0|\n",
      "|Using Storytellin...|             75.0| 0.2041241452319315|  4.0|\n",
      "|   Python Epiphanies|74.18300653594773|0.21683000379251555|  6.0|\n",
      "|Mastering Python ...|             74.0|  0.274620950888068|  4.0|\n",
      "+--------------------+-----------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_scores = spark.sql(\"select exam, avg(score)*100 as `avg_score`, std(score) as `std`, avg(total) as `num_q` \\\n",
    "                        from (select exam, (correct / total) as score, total from ct) group by exam order by avg_score desc\")\n",
    "\n",
    "avg_scores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 'Client-Side Data Storage for Web Developers' had the lowest average score with an average score of 20 and standard deviation of around 0.283. The exams with the highest average score were 'Learning to Visualize Data with D3.js', 'Nulls, Three-valued Logic and Missing Information', and 'The Closed World Assumption'. The average scores for these exams were 100. There does not seem to be a correlation between the number of questions on an exam and the score, as there seems to be a similar pattern of variety in the number of questions for both exams with high average scores and exams with low average scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question: How many unique user_exam_ids exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|unique_id|\n",
      "+---------+\n",
      "|     3242|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uniq_user = spark.sql(\"select count(distinct(user_exam_id)) as unique_id from assessments\")\n",
    "uniq_user.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 3242 unique user_exam_ids exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: How many exams does each person take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----+\n",
      "|user_exam_id                        |count|\n",
      "+------------------------------------+-----+\n",
      "|1e325cc1-47a9-4808-8f6b-508b5459ed6d|3    |\n",
      "|b7ac6d15-97e1-4e94-a09d-da819024b8cd|3    |\n",
      "|a244c11a-d890-4e3e-893d-d17c5ce2ad05|3    |\n",
      "|3d63ec69-8d97-4f99-82aa-b0786ef21679|3    |\n",
      "|028ad26f-a89f-4a63-95d4-b6b58f6fa30d|3    |\n",
      "|fa23b287-0d0a-4683-8d19-38a65b7f57d1|3    |\n",
      "|00745aef-f3af-4127-855c-afc3b6ef4011|3    |\n",
      "|cdc5859d-b332-4fb1-aae4-5cacb52cea5f|3    |\n",
      "|37cf5b0c-4807-4214-8426-fb1731b57700|3    |\n",
      "|ac80a11a-2e79-40ef-a756-7edb6f0ddf0b|3    |\n",
      "|949aa36c-74c7-4fc1-a41f-42386c1beb37|3    |\n",
      "|c320d47f-60d4-49a5-9d6c-67e947979bf0|3    |\n",
      "|bd96cfbe-1532-4ba2-a504-7e8a437a5065|3    |\n",
      "|d4ab4aeb-1368-4866-bc5e-7eee69fd1608|3    |\n",
      "|a7e6fc04-245f-4e3c-9539-e2aac44c0eb8|3    |\n",
      "|a45b5ee6-a4ed-4b18-b962-15abddd765d7|3    |\n",
      "|66d91177-c436-4ee1-b0b0-daa960e1b2d0|3    |\n",
      "|6132da16-2c0c-436c-9c48-43b8bafe0978|3    |\n",
      "|c1eb4d4a-d6ef-43ee-9ef4-58bc6c1d17ff|2    |\n",
      "|6e4889ab-5978-44b9-832f-6243300e401f|2    |\n",
      "+------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exam_per_user = spark.sql(\"select user_exam_id, count(*) as `count` from assessments \\\n",
    "                            group by user_exam_id order by count desc\")\n",
    "exam_per_user.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: A person, represented by a unique user_exam_id, has taken a range of 1 to 3 exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Write to HDFS in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset\n",
    "extracted_assessments.write.mode('overwrite').parquet(\"/tmp/extracted_assessments\") \n",
    "\n",
    "# number of total assessments\n",
    "num_assessments.write.mode('overwrite').parquet(\"/tmp/num_assessments\") \n",
    "\n",
    "# number of people taking learning git\n",
    "learn_git.write.mode('overwrite').parquet(\"/tmp/learn_git\") \n",
    "\n",
    "# least and most common courses taken\n",
    "com_course.write.mode('overwrite').parquet(\"/tmp/com_course\") \n",
    "\n",
    "# number of correct questions and num of total questions per exam\n",
    "my_correct_total.write.mode('overwrite').parquet(\"/tmp/my_correct_total\") \n",
    "\n",
    "# number of questions per exam\n",
    "num_q.write.mode('overwrite').parquet(\"/tmp/num_q\") \n",
    "\n",
    "# average number of questions for all assessments\n",
    "avg_q.write.mode('overwrite').parquet(\"/tmp/avg_q\") \n",
    "\n",
    "# average score, standard deviation, and number of questions per exam\n",
    "avg_scores.write.mode('overwrite').parquet(\"/tmp/avg_scores\") \n",
    "\n",
    "# number of unique user ids\n",
    "uniq_user.write.mode('overwrite').parquet(\"/tmp/uniq_user\") \n",
    "\n",
    "# number of exams a person has taken\n",
    "exam_per_user.write.mode('overwrite').parquet(\"/tmp/exam_per_user\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
